{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFMCdVJIIraw"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "ZxMYj8OpIrCp"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "x00t_uJCEbeb"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q tensorflow_text\n",
    "!pip install -q simpleneighbors[annoy]\n",
    "!pip install -q nltk\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "DmeFAuVsyWxg"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import simpleneighbors\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_text import SentencepieceTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def display_nearest_neighbors(query_text, answer_text=None):\n",
    "  query_embedding = model.signatures['question_encoder'](tf.constant([query_text]))['outputs'][0]\n",
    "  search_results = index.nearest(query_embedding, n=num_results)\n",
    "  for response in search_results:\n",
    "    print(response, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4scA6pE5Rpri"
   },
   "outputs": [],
   "source": [
    "with open('all.txt', encoding='utf_8_sig') as f:\n",
    "    all = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lF27aQTaahCh"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(1, len(all) - 1):\n",
    "    sentence = all[i]\n",
    "    context = all[i - 1] + all[i] + all[i + 1]\n",
    "    sentences.append(tuple([sentence, context]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44I0uCRQRiFO"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\"\n",
    "model = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwDUryIfSLp2"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "encodings = model.signatures['response_encoder'](\n",
    "  input=tf.constant([sentences[0][0]]),\n",
    "  context=tf.constant([sentences[0][1]]))\n",
    "index = simpleneighbors.SimpleNeighbors(\n",
    "    len(encodings['outputs'][0]), metric='angular')\n",
    "\n",
    "print('Computing embeddings for %s sentences' % len(sentences))\n",
    "slices = zip(*(iter(sentences),) * batch_size)\n",
    "num_batches = int(len(sentences) / batch_size)\n",
    "for s in tqdm(slices, total=num_batches):\n",
    "  response_batch = list([r for r, c in s])\n",
    "  context_batch = list([c for r, c in s])\n",
    "  encodings = model.signatures['response_encoder'](\n",
    "    input=tf.constant(response_batch),\n",
    "    context=tf.constant(context_batch)\n",
    "  )\n",
    "  for batch_index, batch in enumerate(response_batch):\n",
    "    index.add_one(batch, encodings['outputs'][batch_index])\n",
    "\n",
    "index.build()\n",
    "print('simpleneighbors index for %s sentences built.' % len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7_RTRing69V"
   },
   "outputs": [],
   "source": [
    "num_results = 5 \n",
    "my_question = 'Привет!'\n",
    "display_nearest_neighbors(my_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv45BCynWilK"
   },
   "outputs": [],
   "source": [
    "index.save('data.pickle')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ОБУЧЕНИЕ \"Universal Encoder Q&A Model Retrieval Demo\"",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
