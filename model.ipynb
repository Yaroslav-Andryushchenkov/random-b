{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ОБУЧЕНИЕ \"Universal Encoder Q&A Model Retrieval Demo\"",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFMCdVJIIraw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "ZxMYj8OpIrCp"
      },
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "x00t_uJCEbeb"
      },
      "source": [
        "%%capture\n",
        "!pip install -q tensorflow_text\n",
        "!pip install -q simpleneighbors[annoy]\n",
        "!pip install -q nltk\n",
        "!pip install -q tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "DmeFAuVsyWxg"
      },
      "source": [
        "import nltk\n",
        "import simpleneighbors\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_text import SentencepieceTokenizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def display_nearest_neighbors(query_text, answer_text=None):\n",
        "  query_embedding = model.signatures['question_encoder'](tf.constant([query_text]))['outputs'][0]\n",
        "  search_results = index.nearest(query_embedding, n=num_results)\n",
        "  for response in search_results:\n",
        "    print(response, end='')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4scA6pE5Rpri"
      },
      "source": [
        "with open('all.txt', encoding='utf_8_sig') as f:\n",
        "    all = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF27aQTaahCh"
      },
      "source": [
        "sentences = []\n",
        "for i in range(1, len(all) - 1):\n",
        "    sentence = all[i]\n",
        "    context = all[i - 1] + all[i] + all[i + 1]\n",
        "    sentences.append(tuple([sentence, context]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44I0uCRQRiFO"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\"\n",
        "model = hub.load(module_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwDUryIfSLp2"
      },
      "source": [
        "#Обучение модели\n",
        "batch_size = 100\n",
        "\n",
        "encodings = model.signatures['response_encoder'](\n",
        "  input=tf.constant([sentences[0][0]]),\n",
        "  context=tf.constant([sentences[0][1]]))\n",
        "index = simpleneighbors.SimpleNeighbors(\n",
        "    len(encodings['outputs'][0]), metric='angular')\n",
        "\n",
        "print('Computing embeddings for %s sentences' % len(sentences))\n",
        "slices = zip(*(iter(sentences),) * batch_size)\n",
        "num_batches = int(len(sentences) / batch_size)\n",
        "for s in tqdm(slices, total=num_batches):\n",
        "  response_batch = list([r for r, c in s])\n",
        "  context_batch = list([c for r, c in s])\n",
        "  encodings = model.signatures['response_encoder'](\n",
        "    input=tf.constant(response_batch),\n",
        "    context=tf.constant(context_batch)\n",
        "  )\n",
        "  for batch_index, batch in enumerate(response_batch):\n",
        "    index.add_one(batch, encodings['outputs'][batch_index])\n",
        "\n",
        "index.build()\n",
        "print('simpleneighbors index for %s sentences built.' % len(sentences))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7_RTRing69V"
      },
      "source": [
        "num_results = 5 \n",
        "my_question = 'Привет!'\n",
        "display_nearest_neighbors(my_question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv45BCynWilK"
      },
      "source": [
        "index.save('data.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}